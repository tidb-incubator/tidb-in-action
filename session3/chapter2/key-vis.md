## 识别集群热点和业务模式

### 概念

- Bucket

  一个 TiDB 集群中，Region（即一个数据块） 的数量可能多达数十万。一般难以将这么多的 Region 信息
  显示在一个屏幕上。因此，在一张热力图中，Region 会被压缩到约 1500 个连续范围，每个范围称为「Bucket」。
  Region 压缩总是倾向于将流量较小的大量 Region 压缩为一个 Bucket，而尽量让高流量的 Region 独立成 Bucket，
  以便突出热点情况。

- 热力图

  热力图是热点可视化的核心，它显示了一个指标随时间的变化。热力图的横轴 X 是时间，纵
  轴 Y 则表示集群里面的 Region，横跨 TiDB 集群上所有数据库和数据表。颜色越暗（cold）
  表示该区域的 Region 在这个时间段上读写流量较低，颜色越亮（hot）表示读写流量越高，即越热。

### 界面图示

借用官方文档里的一个热点示例图，可以观察到以下信息：

- 一个大型热力图，显示访问流量随时间的变化情况
- 下方和右侧为沿热力图的每个轴的平均值
- 左侧为表名、索引名等信息

![](/res/session3/chapter2/keyvis/overview.png)

热点的本质是大多数读写流量都只涉及个别 Region，进而导致集群中只有个别 TiKV 节点承载了大部分操作。KeyVis 将所有 Region 的读写流量按时间依次展示出来，使用颜色明暗表示读写流量的多少，以热力图的方式呈现。
通常业务在访问数据库的时候都有特定的模式，这些模式在数据库的监控系统的往往难以识别，需要数据库专家或者资深的 DBA 靠自己多年丰富的经验仔细的推测。所有业务开发人员可能会经常被问到一些问题，比如：

- 访问数据库有什么特征？
- 读多写少还是写多读少？
- 读写比例是怎样的？
- 有没有热点？
- 追加写还是随机写？
- 一直均匀的读写还是有周期性流量（比如每小时一次促销）？
- 有没有突发性流量？
- 如果业务发展了，是否存在设计瓶颈，能不能 scale 10 倍？
- 有没有扫表(其实就是顺序读)？

业务开发人员面对这些问题有时候一脸问号，脑子里面快速过了一遍自己的业务，我大概有 一百多张表，每个都有增删改查/CRUD，还有各种统计汇总的业务，有很多请求还是用户触发的，这些问题真的是很难回答。很多业务的访问模式都可以在 TiDB dashboard 里面比较直观的观测到， DBA 和开发者能够一眼发现系统的读写比例，哪里有热点，甚至能够精确到哪个数据块，哪些索引，也能预测如果流量持续增长，数据库系统是否能够轻松扩展。

### 几种常见的访问模式

- 顺序读写

  这里是一个三张表的顺序写入的截图，用的 (sysbench prepare 命令)最左边我们可以看到表名为 sbtest1, sbtest2, sbtest3, 注意观察黄色（最亮的）的区块，大体上呈现是一个向上的斜线，这里的颜色亮度越高代表的数据写得越多

  ![](/res/session3/chapter2/keyvis/sequential.png)

* 持续热点

  通常如果业务有持续的热点，在 KeyVis 上也是一眼就看出来了，如下图，可以看到连续的金黄色光条，每个光条代表一段持续的热点块

  ![](/res/session3/chapter2/keyvis/hot.png)

如果我们把光标移动到金黄色的热点上还能看到更具体的提示，如下图所示，可以看到每分钟的流量为 165.25 兆/每秒, 访问的表名是 sbtest1， 访问的对象是表的一个索引，索引的名字是 k_1, 我们也能看到这个块在存储层对应的 key 范围，即图中展示的 start key 和 end key。

![](/res/session3/chapter2/keyvis/tooltip.png)

- 均匀分布

  相信聪明的同学已经猜出来了，其实没有明显热点的就是均为负载，有兴趣的同学自己动手尝试构造一个类似的负载。这种负载下数据库有完美的扩展性，随着业务的流量上升做好扩容操作即可，流量下来了直接缩容。

  ![](/res/session3/chapter2/keyvis/well-dist.png)

- 周期性负载

  系统的负载每隔一段实际会上来一次，随后又下降，如此反复，比如定时任务，整点促销，这些从图上看一目了然

  ![](/res/session3/chapter2/keyvis/periodic.png)

如果大家用的 TiDB 4.0 或者以上的版本，系统会自动根据负载情况来弹性伸缩，不再需要人工干预。弹性伸缩相关的细节请参考弹性调度章节。
